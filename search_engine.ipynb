{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/usr/local/lib/python3.4/dist-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "es = Elasticsearch([{'host': 'localhost', 'port': 9200}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/davidstap/anaconda3/Applications\n",
      "/home/davidstap/anaconda3/Applications/elasticsearch-1.7.1\n"
     ]
    }
   ],
   "source": [
    "% cd Applications\n",
    "% cd elasticsearch-1.7.1\n",
    "!./bin/elasticsearch -d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Assignment  week 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook made by   (If not filled in correctly: 0 pts for assignment)\n",
    "\n",
    "__Name(s)__: \n",
    "\n",
    "__Student id(s)__ : \n",
    "\n",
    "### Pledge (taken from [Coursera's Honor Code](https://www.coursera.org/about/terms/honorcode) )\n",
    "\n",
    "\n",
    "\n",
    "Put here a selfie with your photo where you hold a signed paper with the following text: (if this is team work, put two selfies here). The link must be to some place on the web, not to a local file. **Assignments without the selfies will not be graded and receive 0 points.**\n",
    "\n",
    "> My answers to homework, quizzes and exams will be my own work (except for assignments that explicitly permit collaboration).\n",
    "\n",
    ">I will not make solutions to homework, quizzes or exams available to anyone else. This includes both solutions written by me, as well as any official solutions provided by the course staff.\n",
    "\n",
    ">I will not engage in any other activities that will dishonestly improve my results or dishonestly improve/hurt the results of others.\n",
    "\n",
    "<img src='link to your selfie'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "from xml.dom.minidom import parse, parseString\n",
    "\n",
    "# open and read gzipped xml file\n",
    "infile = gzip.open('../../telegraaf/telegraaf-1951.xml.gz')\n",
    "content = infile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<pm:KBroot xmlns:pm=\"http://www.politicalmashup.nl\" recordfile=\"\">\\n<pm:root><pm:docinfo/><pm:meta><dc:date xmlns:dc=\"http://purl.org/dc/elements/1.1/\">1951-07-02</dc:date><dc:subject xmlns:dc=\"http://purl.org/dc/elements/1.1/\">artikel</dc:subject><dc:identifier xmlns:dc=\"http://purl.org/dc/elements/1.1/\">ddd:011140123:mpeg21:p001:a0001</dc:identifier><dc:source xmlns:dc=\"http://purl.org/dc/elements/1.1/\"><dc:source><pm:link pm:source=\"832675288\" pm:description=\"De Telegraaf\"/></dc:source></dc:source></pm:meta><pm:content pm:source=\"http://kranten.kb.nl/view/article/id/ddd:011140123:mpeg21:p001:a0001\" pm:id=\"ddd:011140123:mpeg21:p001:a0001\"><title pm:id=\"ddd:011140123:mpeg21:p001:a0001.t\">Ook Noord-Korea en China willen praten over wapenstilstand RIDGWAY\\'S OPROEP AANVAARD Ontmoeting bij Kaesong (aan 38ste) voorgesteld MAAR EERST OVER 10 \\xc3\\x80 14 DAGEN</title><text><p pm:id=\"ddd:011140123:mpeg21:p001:a0001.1\">TOKIO, 2 Juli. \\xe2\\x80\\x94 De opperbevelhebbers van'\n"
     ]
    }
   ],
   "source": [
    "print(content[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xmltodict, json\n",
    "\n",
    "o = xmltodict.parse(content)\n",
    "\n",
    "# use xmltodict to convert xml file to json (elasticsearch needs json input)\n",
    "#make json dump\n",
    "dump = json.(o) # '{\"e\": {\"a\": [\"text\", \"text\"]}}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GET DATE FROM ARTICLE\n",
    "def get_date(i):\n",
    "    return o['pm:KBroot']['pm:root'][i]['pm:meta']['dc:date']['#text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GET TITEL FROM ARTICLE\n",
    "def get_title(i):\n",
    "    try:\n",
    "        return o['pm:KBroot']['pm:root'][i]['pm:content']['title']['#text']\n",
    "    except (KeyError):\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GET TEXT FROM ARTICLE\n",
    "def get_text(i):\n",
    "    #sometimes, articles have more than 1 #text field\n",
    "    try:\n",
    "        return o['pm:KBroot']['pm:root'][i]['pm:content']['text']['p']['#text']\n",
    "    except (TypeError):\n",
    "        try:\n",
    "            text = ''\n",
    "            for j in range(len(o['pm:KBroot']['pm:root'][i]['pm:content']['text']['p'])):\n",
    "                text = text + o['pm:KBroot']['pm:root'][i]['pm:content']['text']['p'][j]['#text']\n",
    "            return text\n",
    "        except (TypeError):\n",
    "            return ''\n",
    "    except (KeyError):\n",
    "        return ''\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('@pm:source', 'http://kranten.kb.nl/view/article/id/ddd:011140134:mpeg21:p002:a0024'), ('@pm:id', 'ddd:011140134:mpeg21:p002:a0024'), ('title', OrderedDict([('@pm:id', 'ddd:011140134:mpeg21:p002:a0024.t')])), ('text', None)])"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o['pm:KBroot']['pm:root'][2603]['pm:content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_text(2603)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "telegraaf = list()\n",
    "\n",
    "for i in range(len(o['pm:KBroot']['pm:root'])):\n",
    "    telegraaf.append({'_type':'article', '_index':'telegraaf', 'id':i, 'date':get_date(i), 'title':get_title(i), 'text':get_text(i)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'De eerste dag werd in de Olym. piajollen een hevije strijd geleverd tussen de oude en nieuwe kampi. oen, resp. Koos de Jong en Markus. Beiden gaven geen haarbreed toe, maar het was ten slotte De Jong, die ziin „Zomerweelde\" het eerst over de finish bracht. Ook de Zondagrace was voor hem. Zijn zoontje heeft ook blijkbaar het zeilersbloed geërfd, het behield namelijk in beiae wedstrijden de leiding in de jeugdklasse. gevolgd door Kuylaars. In de Sharpies was de Zaterdagwedstrijd nu eens voor T. Kraan, die in de boot van zijr. broer voer. Zondag was S. J. Kraan, in eigen schip, hem echter verre de baps. CruldeTiond leverde met twee twee. de prijzen lang geen onverdiensto\\' lijke prestatie. In de Pampusklasse vprsloeg Van de Berg Zondag zowel de nationale kampioen Volker als Van Staveren, die men vooral op eigen terrein niet mag onderschatten. Rest nog te vermelden, dat de wedstrijden in ren sportieve sfeer werden venreild, hetseen wel hieruit blijkt, dat er niet één protest is binnengekomen.'"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_text(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NEXT STEP: DUMP TELEGRAAF LIST TO ELASTICSEARCH (SEE TUTORIAL NOTEBOOK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make 1 big json object4\n",
    "# store this in elasticsearch\n",
    "# find document types (for facets)\n",
    "\n",
    "# store these things in elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37375"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(o['pm:KBroot']['pm:root'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create index telegraaf\n",
    "es.indices.create('telegraaf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# delete index telegraaf\n",
    "#es.indices.delete(index='telegraaf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_shards': {'failed': 0, 'successful': 5, 'total': 5}, 'count': 0}"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.count(index='david')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_shards': {'failed': 0, 'successful': 5, 'total': 5},\n",
       " 'hits': {'hits': [{'_id': 'AVgCbyEUpwdMr7iZJqhC',\n",
       "    '_index': 'david',\n",
       "    '_score': 4.0445223,\n",
       "    '_source': {'id': 34, 'letters': 'aJ'},\n",
       "    '_type': 'foo'},\n",
       "   {'_id': 'AVgCbwajpwdMr7iZJqfe',\n",
       "    '_index': 'david',\n",
       "    '_score': 3.9444387,\n",
       "    '_source': {'id': 34, 'letters': 'aJ'},\n",
       "    '_type': 'foo'},\n",
       "   {'_id': 'AVgCbwaipwdMr7iZJqfE',\n",
       "    '_index': 'david',\n",
       "    '_score': 3.5902672,\n",
       "    '_source': {'id': 8, 'letters': 'aj'},\n",
       "    '_type': 'foo'},\n",
       "   {'_id': 'AVgCbyEUpwdMr7iZJqgo',\n",
       "    '_index': 'david',\n",
       "    '_score': 3.5902672,\n",
       "    '_source': {'id': 8, 'letters': 'aj'},\n",
       "    '_type': 'foo'}],\n",
       "  'max_score': 4.0445223,\n",
       "  'total': 4},\n",
       " 'timed_out': False,\n",
       " 'took': 24}"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HOST = 'http://localhost:9200/david'\n",
    "es = Elasticsearch(hosts=[HOST])\n",
    "\n",
    "\n",
    "query={\n",
    "  \"query\": {\n",
    "    \"match\": {'letters':'aj'}\n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "es.search(body=query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment \n",
    "\n",
    "\n",
    "### Standard option\n",
    "<p>Create a search engine for the <a href=\"http://data.politicalmashup.nl/arjan/telegraaf/\">telegraaf newspaper collection</a> using  ElasticSearch. Make facets for years and document types.\n",
    "            Pay attention to telephone numbers (in mini advertisements). Hieronder een voorbeeld van 1 document (= 1 artikeltje).\n",
    "            <br/> Je ziet dat er zelfs een link naar de bron tekst (als plaatje) instaat. De URL linked door naar de nieuwe url <a href=\"http://www.delpher.nl/nl/kranten/view?identifier=ddd%3A010563762%3Ampeg21%3Aa0005&coll=ddd\">http://www.delpher.nl/nl/kranten/view?identifier=ddd%3A010563762%3Ampeg21%3Aa0005&amp;coll=ddd</a>\n",
    "            ElasticSearch gebruikt een JSON formaat als invoer, en dit is dus makkelijk om te zetten naar JSON.</p>\n",
    "<pre>\n",
    "&lt;pm:root>\n",
    "&lt;pm:docinfo/>\n",
    "&lt;pm:meta>\n",
    "&lt;dc:date xmlns:dc=\"http://purl.org/dc/elements/1.1/\">1923-03-01&lt;/dc:date>\n",
    "&lt;dc:subject xmlns:dc=\"http://purl.org/dc/elements/1.1/\">artikel&lt;/dc:subject>\n",
    "&lt;dc:identifier xmlns:dc=\"http://purl.org/dc/elements/1.1/\"\n",
    ">ddd:010563762:mpeg21:p001:a0005&lt;/dc:identifier>\n",
    "&lt;dc:source xmlns:dc=\"http://purl.org/dc/elements/1.1/\">\n",
    "&lt;dc:source>\n",
    "&lt;pm:link pm:source=\"832675288\" pm:description=\"De Telegraaf\"/>\n",
    "&lt;/dc:source>\n",
    "&lt;/dc:source>\n",
    "&lt;/pm:meta>\n",
    "&lt;pm:content pm:source=\"http://kranten.kb.nl/view/article/id/ddd:010563762:mpeg21:p001:a0005\"\n",
    "pm:id=\"ddd:010563762:mpeg21:p001:a0005\">\n",
    "&lt;title pm:id=\"ddd:010563762:mpeg21:p001:a0005.t\">De jongste maaregelen op den Rechter-\n",
    "Rijn-oeven.&lt;/title>\n",
    "&lt;text>\n",
    "&lt;p pm:id=\"ddd:010563762:mpeg21:p001:a0005.1\">â–  volgende redenen rijn bezet: lo. ter vereenvcudi-f\n",
    "ging ran het douane-wezen en 2o. wegens fit' demonstratieÂ» en vergaderingen, welke in deÂ»e gebieden\n",
    "zijn gehouden en gericht waren tegen de bezettingstroepen en de bezettingsautoriteiten. De\n",
    "rijkscommissaris voor de bezette genie den heeft geweigerd, deze kennisgevins door te zenden. â€”\n",
    "(Wolft},&lt;/p>\n",
    "&lt;/text>\n",
    "&lt;/pm:content>\n",
    "&lt;/pm:root>\n",
    "</pre>\n",
    "   \n",
    "### Other options\n",
    "* Provided that you come up with a non trivial collection you can create a search engine using a different collection and also different software, as long as it is not done in MySQL.\n",
    "* Discuss this with the assistants.\n",
    "    * Convince us that your data set is interesting and your software solution worthwhile investigating.\n",
    "* For the presentations it is fun to see something else.\n",
    "* Usually it has a positive effect on your mark if you do something completely different ;-)\n",
    "* You should do the same requirements.\n",
    "\n",
    "#### Examples of other collections\n",
    "* [Hillary Clinton Email collection](https://archive.org/details/hillary-clinton-emails-august-31-release) See also our <http://maartenmarx.nl/teaching/zoekmachines/Data/> folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h2>Requirements</h2>\n",
    "        <p>Each of the following points <strong>must</strong> be addressed. Create a seperate page on the wiki for each point. Make sure these pages can be found from the menu of your wiki. \n",
    "        Explain what you did, and exemplify with links to screenshots/a working system.</p>\n",
    "        <ol>\n",
    "        <li>Search as we know it from Google. Give a result page (SERP), with links to the documents and some description of each hit.</li>\n",
    "            <li>Advanced search. Let a user be able to search in several fields, also in several fields simulteanously. Queries like \"return articles with a title  about XXX  and which are   about YYY in the period ZZZ\" should be possible.\n",
    "             </li>\n",
    "        <li>Do one of the following:\n",
    "            <ol><li>Represent the hits of a query with a wordcloud of 25-50 informative words. The wordcloud should somehow summarise what the collection has to say about the query.\n",
    "            You may think of these words as words that you could add to the query in order to improve recall (blind relevance feedback/query expansion). </li>\n",
    "                <li>Represent each document   with a word-cloud. Also make word-clouds for the question and for the answer.\n",
    "            EXAMPLE: The html files in <a href=\"http://data.politicalmashup.nl/arjan/odeii/data_as_html/\">http://data.politicalmashup.nl/arjan/odeii/data_as_html/</a> contain such wordcloud summaries, which work rather well.</li></ol>\n",
    "        <br/>You can use several techniques to get rid of high frequency, but meaningless words: of course IDF, but also mutual information (see 13.5.1), or of course the technique from the paper by Kaptein et al on wordclouds.\n",
    "        </li>\n",
    "          <!--  <li>Group (nearly) identical documents. It is bad if two or more of the precious places of your top ten hits are occupied by near identical copies of a document.\n",
    "            Even more so if it is not relevant! So, get rid of these, by grouping them for instance. You get an idea of these duplicates if you search for \"neuken\".</li>\n",
    "            -->\n",
    "            <li>Give next to a traditional list of results, a timeline in which you indicate how many hits there are over time.</li>\n",
    "            <li>Provide Faceted Search next to the traditional list of results. For the \"Telegraaf\" collectie, use the <tt>dc:subject</tt> element as facet values.</li>\n",
    "            <li><strong>Evaluate your results</strong> Let 2 persons assess the relevancy of the top 10 documents for <strong>5 different queries</strong>. Compute Cohen's kappa. Determine the average precision at 10 for your system based on these 10 queries, and the two relevance assesments. \n",
    "                Also plot the P@10 (for both judges) for each query, showing differences in hard and easy queries.  \n",
    "                Describe clearly how you solved differences in judgements.\n",
    "            <br/>\n",
    "            Create your queries in the following format:\n",
    "<pre>\n",
    "&lt;topic number=\"6\"  >\n",
    "    &lt;query>kcs&lt;/query>\n",
    "    &lt;description>Find information on the Kansas City Southern railroad.\n",
    "    &lt;/description>\n",
    "\n",
    "&lt;/topic>\n",
    "\n",
    "&lt;topic number=\"16\"  >\n",
    "    &lt;query>arizona game and fish&lt;/query>\n",
    "    &lt;description>I'm looking for information about fishing and hunting\n",
    "    in Arizona.\n",
    "    &lt;/description>\n",
    "&lt;/topic>\n",
    "</pre>\n",
    "    So, both provide the actual query, and a description of the information need that was behind the query.\n",
    "    <br/>\n",
    "    Give a small set of clear guidelines for judging the results, and let your judges follow these guidelines.\n",
    "    <br/>\n",
    "    It is far more interesting to have difficult queries (both for the search engine and for the judges) than to have queries on which all ten retrieved documents are relevant.\n",
    "    So, try to create a good list of information needs.\n",
    "\n",
    "</li>\n",
    "<li>Change the ranking of your system, compute the average precision at 10 using your 10 queries, compare the results to your old system, and EXPLAIN what is going on.</li>\n",
    "</ol>\n",
    "\n",
    "<h2>Presentation</h2>\n",
    "<p>During your presentation you should have a live working search engine, that you demonstrate on the spot. Your presentation should be structured so that you will show all  requirements.\n",
    "You will be asked to show how your system works using information needs coming  from the audience.</p>\n",
    "<p>**Hint:** focus on a special aspect of your project. Everyone has done something similar, so your audience knows what was hard and what was terrible. Pick something you think will interest them.</p>\n",
    "\n",
    "\n",
    "<h2>How you will be marked</h2>\n",
    "<ul>\n",
    "    <li>Sent the URL of your guthub wiki to Maarten Marx BEFORE the presentation.</li>\n",
    "    <li>The first page of the wiki should contain:\n",
    "        <ol>\n",
    "            <li>The names and student numbers of the project members</li>\n",
    "            <li>A link to the slides of your presentation</li>\n",
    "            <li>A table of contents, with links to pages on the wiki adressing one of each of the \"must-have\" points listed above.\n",
    "            <br/>During grading, you will receive points for each of the points. So make it crystal clear where they are adressed in your wiki. Use one page per point.</li>\n",
    "\n",
    "\n",
    "</ol>\n",
    "</li>\n",
    "<li>The page for each point should contain, all rather briefly,\n",
    "<ol>\n",
    "<li>What you did and why you choose to do it in your special way.</li>\n",
    "<li>Examples of what works, and what does not work (very well).</li>\n",
    "<li>An evaluation of the quality of your work in 3-4 sentences.</li>\n",
    "</ol></li>\n",
    "<li>Clickable links to a live working demo are <strong>highly appreciated</strong>. </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
